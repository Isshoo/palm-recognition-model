{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Isshoo/palm-recognition-model/blob/main/Palm_Recognition_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwSsWTxfCiKW"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow opencv-python matplotlib numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrMEOjB-C8km"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l1_l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcOgYKjjDFU-"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive (if your dataset is there)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZwGfPOpDP21"
      },
      "outputs": [],
      "source": [
        "!mkdir -p \"/content/dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUdthR3ADon4"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/drive/MyDrive/palm_dataset/\" \"/content/dataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_9ytPsSEmMi"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "DATASET_PATH = \"/content/drive/MyDrive/gabungan_palm/\"\n",
        "INPUT_SIZE = (256, 256)  # Reduced size for faster processing with small dataset\n",
        "BATCH_SIZE = 8  # Smaller batch size for limited data\n",
        "INITIAL_LR = 1e-4\n",
        "EPOCHS = 100  # More epochs for small dataset with augmentation\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7-4j9pWThi4"
      },
      "outputs": [],
      "source": [
        "# Enhanced random seed setup\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCs8b6Rn22I_"
      },
      "outputs": [],
      "source": [
        "# Performance optimizations\n",
        "tf.config.optimizer.set_experimental_options({'auto_mixed_precision': True})\n",
        "# Enable memory growth to prevent GPU memory issues\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Enable XLA compilation for faster execution\n",
        "tf.config.optimizer.set_jit(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87tMywZTDBly"
      },
      "outputs": [],
      "source": [
        "# Check if dataset exists\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    print(f\"ERROR: Dataset path {DATASET_PATH} not found!\")\n",
        "    print(\"Please check your dataset path.\")\n",
        "else:\n",
        "    CLASS_NAMES = sorted([d for d in os.listdir(DATASET_PATH)\n",
        "                         if os.path.isdir(os.path.join(DATASET_PATH, d))])\n",
        "    print(\"Class names:\", CLASS_NAMES)\n",
        "    print(f\"Number of classes: {len(CLASS_NAMES)}\")\n",
        "\n",
        "    # Check images per class\n",
        "    for class_name in CLASS_NAMES:\n",
        "        class_path = os.path.join(DATASET_PATH, class_name)\n",
        "        image_files = [f for f in os.listdir(class_path)\n",
        "                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        print(f\"Class '{class_name}': {len(image_files)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veLU4-gN-QIl"
      },
      "outputs": [],
      "source": [
        "def enhanced_palm_preprocessing(image_path, visualize=False):\n",
        "    \"\"\"\n",
        "    Enhanced preprocessing specifically for palm line detection\n",
        "    Optimized for rotated palm images without fingers\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not read image: {image_path}\")\n",
        "\n",
        "    steps = []\n",
        "    titles = []\n",
        "\n",
        "    # Apply CLAHE to L channel for better contrast\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    clahe_img = clahe.apply(img)\n",
        "    steps.append(clahe_img)\n",
        "    titles.append(\"Clahe\")\n",
        "\n",
        "    # Denoising with Non-local Means - adjusted parameters\n",
        "    denoised = cv2.fastNlMeansDenoising(clahe_img, None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
        "    steps.append(denoised)\n",
        "    titles.append(\"Denoised\")\n",
        "\n",
        "    # Ridge Enhancement using DoG (Difference of Gaussians)\n",
        "    gauss1 = cv2.GaussianBlur(denoised, (0, 0), sigmaX=0.5)\n",
        "    gauss2 = cv2.GaussianBlur(denoised, (0, 0), sigmaX=1.5)\n",
        "    dog = gauss1 - gauss2\n",
        "    dog = cv2.normalize(dog, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    steps.append(dog)\n",
        "    titles.append(\"DoG Enhancement\")\n",
        "\n",
        "    # Resize with high-quality interpolation\n",
        "    resized = cv2.resize(dog, INPUT_SIZE, interpolation=cv2.INTER_LANCZOS4)\n",
        "    steps.append(resized)\n",
        "    titles.append(\"Resized\")\n",
        "\n",
        "    # Normalize to [0, 1] range\n",
        "    normalized = resized.astype(np.float32) / 255.0\n",
        "    steps.append(normalized)\n",
        "    titles.append(\"Normalized\")\n",
        "\n",
        "    if visualize:\n",
        "        plt.figure(figsize=(18, 12))\n",
        "        for i, (step_img, title) in enumerate(zip(steps, titles), 1):\n",
        "            plt.subplot(2, 5, i)\n",
        "            if len(step_img.shape) == 2:\n",
        "                plt.imshow(step_img, cmap='gray')\n",
        "            else:\n",
        "                plt.imshow(step_img)\n",
        "            plt.title(title, fontsize=10)\n",
        "            plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        return None\n",
        "\n",
        "    return normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2fkq-pwmnru"
      },
      "outputs": [],
      "source": [
        "# Test preprocessing dengan sample image\n",
        "if 'CLASS_NAMES' in locals() and CLASS_NAMES:\n",
        "    sample_class = CLASS_NAMES[0]\n",
        "    class_path = os.path.join(DATASET_PATH, sample_class)\n",
        "    if os.path.exists(class_path):\n",
        "        sample_images = [f for f in os.listdir(class_path)\n",
        "                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        if sample_images:\n",
        "            sample_path = os.path.join(class_path, sample_images[50])\n",
        "            print(f\"Testing preprocessing with: {sample_path}\")\n",
        "            enhanced_palm_preprocessing(sample_path, visualize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-dD0OFLMGWU"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dataset_path, class_names, test_size=0.1, val_size=0.1):\n",
        "    \"\"\"Load and split dataset into train, validation and test sets\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for class_idx, class_name in enumerate(class_names):\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        print(f\"Processing {len(image_files)} images for class {class_name}...\")\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "            try:\n",
        "                processed_img = enhanced_palm_preprocessing(image_path)\n",
        "                images.append(processed_img)\n",
        "                labels.append(class_idx)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # One-hot encode labels\n",
        "    le = LabelEncoder()\n",
        "    labels = le.fit_transform(labels)\n",
        "    labels = to_categorical(labels, num_classes=len(class_names))\n",
        "\n",
        "    # Split into train, validation and test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        images, labels, test_size=test_size, random_state=SEED, stratify=labels\n",
        "    )\n",
        "\n",
        "    # Further split train into train and validation\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=val_size, random_state=SEED, stratify=y_train\n",
        "    )\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUZEk37dilXb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_enhanced_model(input_shape, num_classes):\n",
        "    \"\"\"Create enhanced model with more regularization\"\"\"\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),  # 1 channel karena grayscale\n",
        "\n",
        "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(num_classes, activation='softmax')  # output layer\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5VTk612FSpa"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test) = load_dataset(DATASET_PATH, CLASS_NAMES)\n",
        "\n",
        "print(f\"\\nDataset shapes:\")\n",
        "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation: {X_val.shape}, {y_val.shape}\")\n",
        "print(f\"Test: {X_test.shape}, {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SXKZleVMjNw"
      },
      "outputs": [],
      "source": [
        "# Create enhanced model\n",
        "print(\"\\nCreating enhanced model...\")\n",
        "model = create_enhanced_model((INPUT_SIZE[0], INPUT_SIZE[1], 1), len(CLASS_NAMES))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7a_Ou4rF2Li"
      },
      "outputs": [],
      "source": [
        "# Enhanced callbacks\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        'best_model.keras',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        mode='max',\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37assU3tF9bS"
      },
      "outputs": [],
      "source": [
        "# Enhanced training with class weights\n",
        "print(\"\\nTraining enhanced model...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTzOUlfht51j"
      },
      "outputs": [],
      "source": [
        "# Load best model\n",
        "model.load_weights('debug_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IryEOoqWt8h0"
      },
      "outputs": [],
      "source": [
        "# Evaluate\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EVALUATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"Train Accuracy: {train_acc*100:.2f}%\")\n",
        "print(f\"Validation Accuracy: {val_acc*100:.2f}%\")\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes,\n",
        "                          target_names=CLASS_NAMES, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgJQDq3oaXUp"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp5pvCcouhXq"
      },
      "outputs": [],
      "source": [
        "# Show some predictions\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"SAMPLE PREDICTIONS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Show first few test predictions\n",
        "for i in range(min(5, len(X_test))):\n",
        "    true_class = CLASS_NAMES[y_true_classes[i]]\n",
        "    pred_class = CLASS_NAMES[y_pred_classes[i]]\n",
        "    confidence = y_pred[i][y_pred_classes[i]]\n",
        "\n",
        "    print(f\"Sample {i+1}: True={true_class}, Pred={pred_class}, Confidence={confidence:.3f}\")\n",
        "\n",
        "    # Show image\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(X_test[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"True: {true_class}\\nPred: {pred_class} ({confidence:.3f})\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnQKjNWoyx8e"
      },
      "outputs": [],
      "source": [
        "# Save final model\n",
        "model.save('final_palm_recognition_model.keras')\n",
        "print(\"\\nModel saved as 'final_palm_recognition_model.keras'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUTYz2iGF6WK"
      },
      "outputs": [],
      "source": [
        "# Convert to TFLite (optional)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('palm_line_detection.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Model saved in H5 and TFLite formats!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3wFHB4ijHHM"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "## 9. Inference Example\n",
        "\"\"\"\n",
        "\n",
        "def predict_image(image_path, model, class_names):\n",
        "    \"\"\"Make prediction on a single image\"\"\"\n",
        "    # Preprocess image\n",
        "    processed_img = preprocessing_image(image_path)\n",
        "\n",
        "    # Add batch dimension\n",
        "    input_img = np.expand_dims(processed_img, axis=0)\n",
        "\n",
        "    # Make prediction\n",
        "    predictions = model.predict(input_img)\n",
        "    predicted_class = np.argmax(predictions)\n",
        "    confidence = np.max(predictions)\n",
        "\n",
        "    # Display results\n",
        "    plt.figure(figsize=(8, 4))\n",
        "\n",
        "    # Original image\n",
        "    original_img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(original_img)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Processed image with prediction\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(processed_img)\n",
        "    plt.title(f\"Predicted: {class_names[predicted_class]}\\nConfidence: {confidence:.2f}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return class_names[predicted_class], confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG-PvUZMjPlw"
      },
      "outputs": [],
      "source": [
        "# Test prediction\n",
        "sample_image = os.path.join(DATASET_PATH, CLASS_NAMES[1], os.listdir(os.path.join(DATASET_PATH, CLASS_NAMES[1]))[14])\n",
        "pred_class, confidence = predict_image(sample_image, model, CLASS_NAMES)\n",
        "print(f\"Predicted class: {pred_class} with confidence {confidence:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}